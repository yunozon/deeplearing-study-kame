{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d1f4e28-a714-4770-a37c-ece0da05910a",
   "metadata": {},
   "source": [
    "# backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b2621-dd56-4f8b-847d-68dc32e59252",
   "metadata": {},
   "source": [
    "## backwardを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1df8216c-ccf4-4fa4-9437-662fa1e0702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "916be61d-3a7d-4e29-8f20-d0a972a0c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(A, W, b, Z):\n",
    "    W.grad_ = Z.grad_.T @ A\n",
    "    b.grad_ = torch.sum(Z.grad_, dim=0)\n",
    "    A.grad_ = Z.grad_ @ W\n",
    "\n",
    "def relu_backward(Z, A):\n",
    "    Z.grad_ = A.grad_ * (Z > 0).float()\n",
    "\n",
    "# softmax\n",
    "def softmax(x):\n",
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    return e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "\n",
    "# cross_entropy\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    return torch.sum(y_true * torch.log(y_pred)) / y_true.shape[0]\n",
    "\n",
    "# softmax関数とcross_entropyを一つにまとめる\n",
    "def softmax_cross_entropy(x, y_true):\n",
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    softmax_out = e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "    loss = -torch.sum(y_true * torch.log(softmax_out + 1e-10)) / y_true.shape[0]\n",
    "    return loss, softmax_out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1dac4d91-f71e-4afe-a013-09c3f5aebefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def linear(X, W, b):\n",
    "    return X@W.T + b\n",
    "\n",
    "def relu(Z):\n",
    "    # .clapm_minの中より小さいのは()で置き換える\n",
    "    return Z.clamp_min(0.)\n",
    "\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    \n",
    "    # 出力層\n",
    "    loss, A2 = softmax_cross_entorpy(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    Z2.grad_ = (A2 - y)/ X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fcda9f-5824-444c-b4d1-062fb8be8c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6993b58-ae6f-4bf0-9b9b-d6118b192828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc24b27-b6ab-4a01-b004-33ebed1e449f",
   "metadata": {},
   "source": [
    "## Autogradとスクラッチで実装したbackpropagationが一致することを確かめる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f5c0539-621e-4700-826d-f912cc4b55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータをロード\n",
    "dataset = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7c0f00f-9f94-46e8-a6e2-060644b2ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = dataset['images']\n",
    "target = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "32f61cd2-cdae-4e7f-9aa5-fbd4568d7c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "# 確認\n",
    "print(images.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93b38835-8437-47c3-856b-5175095a62f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理と画像の標準化とデータ分割\n",
    "# データの分割\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# one-hot\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes = 10)\n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 64)\n",
    "# import pdb; pdb.set_trace()\n",
    "X_val  = torch.tensor(X_val, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "# 標準化\n",
    "X_mean = X_train.mean()\n",
    "X_std = X_train.std()\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_val =  (X_val - X_mean) / X_std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81ab2c9e-112f-418c-b07f-62bc6001a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# パラメータの初期化\n",
    "nh = 30\n",
    "class_num = 10\n",
    "m, n = X_train.shape # 入力\n",
    "\n",
    "# W1 = torch.randn((nh, n), requires_grad=True)\n",
    "W1 = torch.randn((nh, n ) ) * torch.sqrt(torch.tensor((2./n)))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad=True)\n",
    "\n",
    "# W2 = torch.randn((class_num, nh), requires_grad=True)\n",
    "W2 = torch.randn((class_num, nh ) ) * torch.sqrt(torch.tensor((2./nh)))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad=True)\n",
    "\n",
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train)\n",
    "loss.backward()\n",
    "\n",
    "# autogradと等しいことを確認する\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1dffb83a-541f-436e-9a2a-d7f75f42f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2174e-03, -1.3511e-03,  6.1334e-07,  ..., -2.3137e-04,\n",
       "         -1.9084e-03, -1.2174e-03],\n",
       "        [-1.0238e-02, -8.5031e-03,  1.1822e-02,  ..., -7.3752e-03,\n",
       "         -2.1876e-02, -1.2010e-02],\n",
       "        [ 5.6885e-03,  8.3885e-03,  1.1831e-02,  ..., -6.6835e-03,\n",
       "          1.4025e-02,  7.0614e-03],\n",
       "        ...,\n",
       "        [-3.5550e-04, -4.0596e-03, -2.1640e-02,  ..., -5.0139e-02,\n",
       "         -8.0396e-03, -4.6834e-04],\n",
       "        [-5.9436e-02, -6.1237e-02, -3.8506e-02,  ...,  3.7576e-02,\n",
       "         -3.2430e-02, -4.8552e-02],\n",
       "        [-2.0860e-03, -1.1502e-03,  2.5302e-03,  ..., -2.2132e-02,\n",
       "         -5.9467e-03, -1.8114e-03]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8714d-fc4c-4b47-af33-b53ec0cb5aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "554000f7-37d2-47fa-9d98-5251d0543d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2174e-03, -1.3511e-03,  6.1343e-07,  ..., -2.3137e-04,\n",
       "         -1.9084e-03, -1.2174e-03],\n",
       "        [-1.0238e-02, -8.5031e-03,  1.1822e-02,  ..., -7.3752e-03,\n",
       "         -2.1876e-02, -1.2010e-02],\n",
       "        [ 5.6885e-03,  8.3885e-03,  1.1831e-02,  ..., -6.6835e-03,\n",
       "          1.4025e-02,  7.0614e-03],\n",
       "        ...,\n",
       "        [-3.5550e-04, -4.0596e-03, -2.1640e-02,  ..., -5.0139e-02,\n",
       "         -8.0396e-03, -4.6834e-04],\n",
       "        [-5.9436e-02, -6.1237e-02, -3.8506e-02,  ...,  3.7576e-02,\n",
       "         -3.2430e-02, -4.8552e-02],\n",
       "        [-2.0860e-03, -1.1502e-03,  2.5302e-03,  ..., -2.2132e-02,\n",
       "         -5.9467e-03, -1.8114e-03]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b53be8c7-5b9e-43c2-bba9-afa5625d4d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(759)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(W1.grad_ == W1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b3750a6-f28b-4c7e-9414-4e68d0bc04af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3169e-06,  4.4577e-07,  6.0444e-05,  ...,  9.8272e-06,\n",
       "          2.7154e-06,  1.0628e-05],\n",
       "        [-6.9043e-04,  8.6426e-06,  1.4949e-05,  ...,  7.4142e-05,\n",
       "          1.2745e-04,  4.6533e-05],\n",
       "        [-6.9520e-04,  3.0745e-06,  5.9431e-05,  ...,  8.0557e-05,\n",
       "          1.1413e-05,  6.5011e-05],\n",
       "        ...,\n",
       "        [ 2.1566e-05,  5.2735e-06, -6.6634e-04,  ...,  3.8326e-05,\n",
       "          9.8389e-05,  1.0916e-05],\n",
       "        [ 1.1258e-06,  8.0442e-06,  2.3198e-05,  ..., -5.2240e-04,\n",
       "          2.0230e-04,  1.4130e-05],\n",
       "        [ 4.0691e-06, -6.8526e-04,  8.0865e-05,  ...,  1.3706e-04,\n",
       "          1.3624e-04,  3.6407e-05]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2.grad_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eef2c943-923f-42b1-b682-c064020eec59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3169e-06,  4.4577e-07,  6.0444e-05,  ...,  9.8272e-06,\n",
       "          2.7154e-06,  1.0628e-05],\n",
       "        [-6.9043e-04,  8.6426e-06,  1.4949e-05,  ...,  7.4142e-05,\n",
       "          1.2745e-04,  4.6533e-05],\n",
       "        [-6.9520e-04,  3.0745e-06,  5.9431e-05,  ...,  8.0557e-05,\n",
       "          1.1413e-05,  6.5011e-05],\n",
       "        ...,\n",
       "        [ 2.1566e-05,  5.2735e-06, -6.6634e-04,  ...,  3.8326e-05,\n",
       "          9.8389e-05,  1.0916e-05],\n",
       "        [ 1.1258e-06,  8.0442e-06,  2.3198e-05,  ..., -5.2240e-04,\n",
       "          2.0230e-04,  1.4130e-05],\n",
       "        [ 4.0691e-06, -6.8526e-04,  8.0865e-05,  ...,  1.3706e-04,\n",
       "          1.3624e-04,  3.6407e-05]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dbf897f3-2d53-43db-b896-4b30e20c63d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6904)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Z2.grad_ == Z2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3200c229-5111-419a-b840-830e35694c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1: train loss : 0.6966667892411351, val loss : 0.2333393543958664, val accuracy 1.0\n",
      "epoch : 2: train loss : 0.20995537509831289, val loss : 0.18444675207138062, val accuracy 1.0\n",
      "epoch : 3: train loss : 0.12166053111044069, val loss : 0.13323885202407837, val accuracy 1.0\n",
      "epoch : 4: train loss : 0.10371072012155007, val loss : 0.17466755211353302, val accuracy 1.0\n",
      "epoch : 5: train loss : 0.07781402996139757, val loss : 0.135255828499794, val accuracy 1.0\n",
      "epoch : 6: train loss : 0.05418967220854635, val loss : 0.12357524037361145, val accuracy 1.0\n",
      "epoch : 7: train loss : 0.050140989401067294, val loss : 0.11388607323169708, val accuracy 1.0\n",
      "epoch : 8: train loss : 0.0428865412104642, val loss : 0.18954601883888245, val accuracy 1.0\n",
      "epoch : 9: train loss : 0.03508908559645837, val loss : 0.1086653620004654, val accuracy 1.0\n",
      "epoch : 10: train loss : 0.030749320110771805, val loss : 0.10592357814311981, val accuracy 1.0\n",
      "epoch : 11: train loss : 0.026157511500059627, val loss : 0.11672511696815491, val accuracy 1.0\n",
      "epoch : 12: train loss : 0.021972411930619273, val loss : 0.10390612483024597, val accuracy 1.0\n",
      "epoch : 13: train loss : 0.020371179295276914, val loss : 0.16762079298496246, val accuracy 1.0\n",
      "epoch : 14: train loss : 0.019420619811474655, val loss : 0.10623358935117722, val accuracy 1.0\n",
      "epoch : 15: train loss : 0.016989726878819056, val loss : 0.10636668652296066, val accuracy 1.0\n",
      "epoch : 16: train loss : 0.014758574759374218, val loss : 0.10628895461559296, val accuracy 1.0\n",
      "epoch : 17: train loss : 0.012812254019081593, val loss : 0.1133023351430893, val accuracy 1.0\n",
      "epoch : 18: train loss : 0.012557863805947514, val loss : 0.11777539551258087, val accuracy 1.0\n",
      "epoch : 19: train loss : 0.009638547129725339, val loss : 0.11562427878379822, val accuracy 1.0\n",
      "epoch : 20: train loss : 0.011311176703505529, val loss : 0.11052786558866501, val accuracy 1.0\n",
      "epoch : 21: train loss : 0.008409965123670796, val loss : 0.1101122722029686, val accuracy 1.0\n",
      "epoch : 22: train loss : 0.007761320661908637, val loss : 0.10637795180082321, val accuracy 1.0\n",
      "epoch : 23: train loss : 0.007204930589068681, val loss : 0.10963781177997589, val accuracy 1.0\n",
      "epoch : 24: train loss : 0.006446945915134468, val loss : 0.11101469397544861, val accuracy 1.0\n",
      "epoch : 25: train loss : 0.006576686865931454, val loss : 0.11257422715425491, val accuracy 1.0\n",
      "epoch : 26: train loss : 0.005821396802275558, val loss : 0.11373542994260788, val accuracy 1.0\n",
      "epoch : 27: train loss : 0.005282805943958617, val loss : 0.1159667894244194, val accuracy 1.0\n",
      "epoch : 28: train loss : 0.004938436473215309, val loss : 0.11612405627965927, val accuracy 1.0\n",
      "epoch : 29: train loss : 0.005014774405935896, val loss : 0.11499374359846115, val accuracy 1.0\n",
      "epoch : 30: train loss : 0.004751054903560241, val loss : 0.11278470605611801, val accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "# バッチサイズ\n",
    "learning_rate = 0.03\n",
    "batch_size = 30\n",
    "num_batches = np.ceil((len(y_train)) / batch_size).astype(int)\n",
    "\n",
    "# パラメータの初期化\n",
    "nh = 30\n",
    "class_num = 10\n",
    "m, n = X_train.shape # 入力\n",
    "\n",
    "# W1 = torch.randn((nh, n), requires_grad=True)\n",
    "W1 = torch.randn((nh, n ) ) * torch.sqrt(torch.tensor((2./n)))\n",
    "W1.requires_grad = True\n",
    "b1 = torch.zeros((1, nh), requires_grad=True)\n",
    "\n",
    "# W2 = torch.randn((class_num, nh), requires_grad=True)\n",
    "W2 = torch.randn((class_num, nh ) ) * torch.sqrt(torch.tensor((2./nh)))\n",
    "W2.requires_grad = True\n",
    "b2 = torch.zeros((1, class_num), requires_grad=True)\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# 学習率の準備\n",
    "learning_rate = 0.3\n",
    "# 各イテレーションの損失を入れる\n",
    "loss_log = []\n",
    "\n",
    "epoches = 30\n",
    "for epoch in range(epoches):\n",
    "    shuffle_indices = np.random.permutation(len(y_train))\n",
    "    running_loss = 0\n",
    "    # それぞれのepochではデータを持ってきて、zを計算損失計算、softmax計算\n",
    "    for i in range(num_batches):\n",
    "\n",
    "        # ミニバッチ作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        batch_indices = shuffle_indices[start:end]\n",
    "        \n",
    "        # 6. 入力データxおよび教師ラベルyを作成\n",
    "        y_true_ = y_train[batch_indices, :]  # データ数 x　クラス数\n",
    "        X = X_train[batch_indices, :] # データ数 x 特徴量\n",
    "        # import pdb; pdb.set_trace()\n",
    "        \n",
    "        # 7. z計算\n",
    "        # Z = X@W.T + b  # -> MLP\n",
    "        Z1 = linear(X, W1, b1)\n",
    "        Z1.retain_grad()\n",
    "        A1 = relu(Z1)\n",
    "        A1.retain_grad()\n",
    "        Z2 = linear(A1, W2, b2)\n",
    "        Z2.retain_grad()\n",
    "\n",
    "        loss, A2 = softmax_cross_entorpy(Z2, y_true_)\n",
    "\n",
    "        # 9. 損失計算\n",
    "        loss_log.append(loss.item())\n",
    "        # epochごとのlossを計算する\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 10. 勾配を計算する\n",
    "        Z2.grad_ = (A2 - y_true_)/ X.shape[0]\n",
    "        linear_backward(A1, W2, b2, Z2)\n",
    "        relu_backward(Z1, A1)\n",
    "        linear_backward(X, W1, b1, Z1)\n",
    "\n",
    "        # 11. パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            W1 -= learning_rate * W1.grad_  # 自作した.grad_\n",
    "            W2 -= learning_rate * W2.grad_  # 自作した.grad_\n",
    "            \n",
    "            b1 -= learning_rate * b1.grad_\n",
    "            b2 -= learning_rate * b2.grad_\n",
    "\n",
    "        # 12. 勾配初期化\n",
    "            W1.grad_ = None\n",
    "            W2.grad_ = None\n",
    "            b1.grad_ = None\n",
    "            b2.grad_ = None\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        Z1_val = linear(X_val, W1, b1)\n",
    "        A1_val = relu(Z1_val)\n",
    "        Z2_val = linear(A1_val, W2, b2)\n",
    "        val_loss,A2_val = softmax_cross_entropy(Z2_val, y_val)\n",
    "\n",
    "        # val_loss = cross_entropy(y_val, y_pred_val)\n",
    "\n",
    "        # accuracy\n",
    "        val_accuracy = torch.sum(torch.argmax(y_val, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy.item())\n",
    "\n",
    "    # 13. 損失logを出力\n",
    "    print(f'epoch : {epoch+1}: train loss : {running_loss/num_batches}, val loss : {val_loss.item()}, val accuracy {val_accuracy.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471815ba-be65-4e0d-82de-1482dcb1068f",
   "metadata": {},
   "source": [
    "### 回帰モデルをスクラッチで実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4a46b517-1075-412c-bdfb-ee5b97db172e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1162775993.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[82], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    linear_backward(A1, W2, b2, Z2)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def mse(X, y):\n",
    "    return (X[:0] - y ).pow(2).mean()\n",
    "\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    \n",
    "    # 出力層\n",
    "    loss = mse(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    # Z2.grad_ = (A2 - y)/ X.shape[0\n",
    "    Z2.grad_ = 2 * (Z2 - y.unsqueeze(dim=-1)/ X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0417bf85-2c88-4f97-9a93-85eb3587fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# データの準備\n",
    "dataset = datasets.load_digits()\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# one-hot\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes = 10)\n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 64)\n",
    "# import pdb; pdb.set_trace()\n",
    "X_val  = torch.tensor(X_val, dtype=torch.float32).reshape(-1, 64)\n",
    "\n",
    "# 標準化\n",
    "X_mean = X_train.mean()\n",
    "X_std = X_train.std()\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_val =  (X_val - X_mean) / X_std\n",
    "\n",
    "\n",
    "# 回帰なのでonehotをする必要なし。これを修正する\n",
    "y_train_reg = torch.argmax(y_train, dim=-1)\n",
    "\n",
    "def mse(X, y):\n",
    "    return (X[:, 0] - y ).pow(2).mean()\n",
    "\n",
    "def forward_and_backward(X, y):\n",
    "    # forward\n",
    "    Z1 = linear(X, W1, b1)\n",
    "    Z1.retain_grad()\n",
    "    A1 = relu(Z1)\n",
    "    A1.retain_grad()\n",
    "    Z2 = linear(A1, W2, b2)\n",
    "    Z2.retain_grad()\n",
    "    \n",
    "    # 出力層\n",
    "    loss = mse(Z2, y)\n",
    "\n",
    "    # backward\n",
    "    Z2.grad_ = 2 * (Z2 - y.unsqueeze(dim=-1))/X.shape[0]\n",
    "    linear_backward(A1, W2, b2, Z2)\n",
    "    relu_backward(Z1, A1)\n",
    "    linear_backward(X, W1, b1, Z1)\n",
    "    return loss, Z1, A1, Z2, A2\n",
    "    \n",
    "\n",
    "# パラメータの初期化\n",
    "nh = 30\n",
    "m, n = X_train.shape # 入力\n",
    "\n",
    "W1 = torch.randn((nh, n), requires_grad=True)\n",
    "b1 = torch.zeros((1, nh), requires_grad=True)\n",
    "\n",
    "W2 = torch.randn((1, nh), requires_grad=True)\n",
    "b2 = torch.zeros((1, 1), requires_grad=True)\n",
    "\n",
    "loss, Z1, A1, Z2, A2 = forward_and_backward(X_train, y_train_reg)\n",
    "loss.backward()\n",
    "\n",
    "# autogradと等しいことを確認する\n",
    "print(torch.allclose(W1.grad_, W1.grad))\n",
    "print(torch.allclose(b1.grad_, b1.grad))\n",
    "print(torch.allclose(W2.grad_, W2.grad))\n",
    "print(torch.allclose(b2.grad_, b2.grad))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ea2ff-ad72-4132-bd59-2abd728726fe",
   "metadata": {},
   "source": [
    "## Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "400b16c7-3f7e-4f4a-8196-60bca6fe9872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0: train error : 2.416108946005503, validation error : 2.1610004901885986,val accuracy 0.2777777910232544\n",
      "epoch : 1: train error : 2.0587645545601845, validation error : 1.9678034782409668,val accuracy 0.34166666865348816\n",
      "epoch : 2: train error : 1.8984086886048317, validation error : 1.8209500312805176,val accuracy 0.3861111104488373\n",
      "epoch : 3: train error : 1.7664701044559479, validation error : 1.704996109008789,val accuracy 0.3888888955116272\n",
      "epoch : 4: train error : 1.6615629196166992, validation error : 1.6097471714019775,val accuracy 0.4055555462837219\n",
      "epoch : 5: train error : 1.5719226474563281, validation error : 1.5283621549606323,val accuracy 0.44999998807907104\n",
      "epoch : 6: train error : 1.4895704612135887, validation error : 1.4531205892562866,val accuracy 0.46666666865348816\n",
      "epoch : 7: train error : 1.4120475475986798, validation error : 1.3794163465499878,val accuracy 0.5083333253860474\n",
      "epoch : 8: train error : 1.3359637074172497, validation error : 1.3100757598876953,val accuracy 0.5444444417953491\n",
      "epoch : 9: train error : 1.2611521482467651, validation error : 1.2438124418258667,val accuracy 0.5972222089767456\n",
      "epoch : 10: train error : 1.1923614740371704, validation error : 1.181547999382019,val accuracy 0.625\n",
      "epoch : 11: train error : 1.1271952949464321, validation error : 1.128157615661621,val accuracy 0.6388888955116272\n",
      "epoch : 12: train error : 1.0691695908705394, validation error : 1.0719577074050903,val accuracy 0.6416666507720947\n",
      "epoch : 13: train error : 1.0161973672608535, validation error : 1.0225332975387573,val accuracy 0.6527777910232544\n",
      "epoch : 14: train error : 0.9668471366167068, validation error : 0.9736020565032959,val accuracy 0.6666666865348816\n",
      "epoch : 15: train error : 0.9205149573584398, validation error : 0.9293431639671326,val accuracy 0.675000011920929\n",
      "epoch : 16: train error : 0.8796619648734728, validation error : 0.8888953924179077,val accuracy 0.6805555820465088\n",
      "epoch : 17: train error : 0.8405499445895354, validation error : 0.8497818112373352,val accuracy 0.6916666626930237\n",
      "epoch : 18: train error : 0.8033417252202829, validation error : 0.814204216003418,val accuracy 0.7083333134651184\n",
      "epoch : 19: train error : 0.7680844285835823, validation error : 0.7784731388092041,val accuracy 0.730555534362793\n",
      "epoch : 20: train error : 0.7344458947579066, validation error : 0.7448186278343201,val accuracy 0.75\n",
      "epoch : 21: train error : 0.7026059584071239, validation error : 0.7122275233268738,val accuracy 0.7888888716697693\n",
      "epoch : 22: train error : 0.6725613847374916, validation error : 0.6812888979911804,val accuracy 0.8138889074325562\n",
      "epoch : 23: train error : 0.6427439500888189, validation error : 0.6490568518638611,val accuracy 0.8305555582046509\n",
      "epoch : 24: train error : 0.6128152124583721, validation error : 0.6172700524330139,val accuracy 0.8527777791023254\n",
      "epoch : 25: train error : 0.5847130821396908, validation error : 0.5891473889350891,val accuracy 0.8583333492279053\n",
      "epoch : 26: train error : 0.5562998459984859, validation error : 0.5601472854614258,val accuracy 0.8666666746139526\n",
      "epoch : 27: train error : 0.5298385160664717, validation error : 0.5311062932014465,val accuracy 0.8722222447395325\n",
      "epoch : 28: train error : 0.5041512083262205, validation error : 0.5039055347442627,val accuracy 0.8805555701255798\n",
      "epoch : 29: train error : 0.48039912215123576, validation error : 0.47837039828300476,val accuracy 0.8861111402511597\n",
      "epoch : 30: train error : 0.4569964421292146, validation error : 0.45904698967933655,val accuracy 0.8888888955116272\n",
      "epoch : 31: train error : 0.4344637185956041, validation error : 0.4371860921382904,val accuracy 0.8833333253860474\n",
      "epoch : 32: train error : 0.41456722747534513, validation error : 0.417585164308548,val accuracy 0.8888888955116272\n",
      "epoch : 33: train error : 0.3966669999063015, validation error : 0.40235236287117004,val accuracy 0.8833333253860474\n",
      "epoch : 34: train error : 0.37946459961434204, validation error : 0.3842560946941376,val accuracy 0.8861111402511597\n",
      "epoch : 35: train error : 0.3639558330178261, validation error : 0.3696613013744354,val accuracy 0.8833333253860474\n",
      "epoch : 36: train error : 0.3492936960731943, validation error : 0.35946622490882874,val accuracy 0.8888888955116272\n",
      "epoch : 37: train error : 0.3365498886754115, validation error : 0.34755125641822815,val accuracy 0.8888888955116272\n",
      "epoch : 38: train error : 0.32494329878439504, validation error : 0.3364160656929016,val accuracy 0.8916666507720947\n",
      "epoch : 39: train error : 0.31385220618297655, validation error : 0.3270973265171051,val accuracy 0.8916666507720947\n",
      "epoch : 40: train error : 0.30496404102693003, validation error : 0.31809696555137634,val accuracy 0.894444465637207\n",
      "epoch : 41: train error : 0.2956543828671177, validation error : 0.3148615062236786,val accuracy 0.8972222208976746\n",
      "epoch : 42: train error : 0.28703110571950674, validation error : 0.3065497577190399,val accuracy 0.8972222208976746\n",
      "epoch : 43: train error : 0.27922977941731614, validation error : 0.2998256981372833,val accuracy 0.8972222208976746\n",
      "epoch : 44: train error : 0.27369923625762266, validation error : 0.29322707653045654,val accuracy 0.9027777910232544\n",
      "epoch : 45: train error : 0.2663747078428666, validation error : 0.2847283184528351,val accuracy 0.9055555462837219\n",
      "epoch : 46: train error : 0.2591668941701452, validation error : 0.28141048550605774,val accuracy 0.9027777910232544\n",
      "epoch : 47: train error : 0.2532342942431569, validation error : 0.2774043679237366,val accuracy 0.9083333611488342\n",
      "epoch : 48: train error : 0.24811336615433296, validation error : 0.2710385322570801,val accuracy 0.9111111164093018\n",
      "epoch : 49: train error : 0.24269735844184956, validation error : 0.2680993676185608,val accuracy 0.9111111164093018\n",
      "epoch : 50: train error : 0.23755423755695423, validation error : 0.26363858580589294,val accuracy 0.9138888716697693\n",
      "epoch : 51: train error : 0.23308439816658696, validation error : 0.2601272165775299,val accuracy 0.9166666865348816\n",
      "epoch : 52: train error : 0.2279920020761589, validation error : 0.2553706169128418,val accuracy 0.9194444417953491\n",
      "epoch : 53: train error : 0.22391914327939352, validation error : 0.25187134742736816,val accuracy 0.9194444417953491\n",
      "epoch : 54: train error : 0.21950866219898066, validation error : 0.24833358824253082,val accuracy 0.9222221970558167\n",
      "epoch : 55: train error : 0.2155283847823739, validation error : 0.2440621554851532,val accuracy 0.9222221970558167\n",
      "epoch : 56: train error : 0.2124612363986671, validation error : 0.24301090836524963,val accuracy 0.9194444417953491\n",
      "epoch : 57: train error : 0.20807403846022984, validation error : 0.2408858686685562,val accuracy 0.9194444417953491\n",
      "epoch : 58: train error : 0.20484574829849103, validation error : 0.23601189255714417,val accuracy 0.9194444417953491\n",
      "epoch : 59: train error : 0.20202445758817097, validation error : 0.23270688951015472,val accuracy 0.9222221970558167\n",
      "epoch : 60: train error : 0.19858711290483674, validation error : 0.22883184254169464,val accuracy 0.9222221970558167\n",
      "epoch : 61: train error : 0.19571809975119928, validation error : 0.22882793843746185,val accuracy 0.9222221970558167\n",
      "epoch : 62: train error : 0.19311592758943638, validation error : 0.2259632796049118,val accuracy 0.9222221970558167\n",
      "epoch : 63: train error : 0.19026359217241406, validation error : 0.2251124531030655,val accuracy 0.9277777671813965\n",
      "epoch : 64: train error : 0.18706227466464043, validation error : 0.21996277570724487,val accuracy 0.9277777671813965\n",
      "epoch : 65: train error : 0.18464405097377798, validation error : 0.2194199413061142,val accuracy 0.9277777671813965\n",
      "epoch : 66: train error : 0.18195562957165143, validation error : 0.21550975739955902,val accuracy 0.9277777671813965\n",
      "epoch : 67: train error : 0.18001251528039575, validation error : 0.21366146206855774,val accuracy 0.9305555820465088\n",
      "epoch : 68: train error : 0.17763262637890875, validation error : 0.21232439577579498,val accuracy 0.9333333373069763\n",
      "epoch : 69: train error : 0.17473705966646472, validation error : 0.21166935563087463,val accuracy 0.9305555820465088\n",
      "epoch : 70: train error : 0.1732988137130936, validation error : 0.20923680067062378,val accuracy 0.9333333373069763\n",
      "epoch : 71: train error : 0.1707809828221798, validation error : 0.2081606090068817,val accuracy 0.9333333373069763\n",
      "epoch : 72: train error : 0.168715386884287, validation error : 0.20391979813575745,val accuracy 0.9333333373069763\n",
      "epoch : 73: train error : 0.16655931202694774, validation error : 0.20301157236099243,val accuracy 0.9361110925674438\n",
      "epoch : 74: train error : 0.16461373205917576, validation error : 0.20231211185455322,val accuracy 0.9361110925674438\n",
      "epoch : 75: train error : 0.16247523133642972, validation error : 0.20216672122478485,val accuracy 0.9361110925674438\n",
      "epoch : 76: train error : 0.1610000766813755, validation error : 0.1986059844493866,val accuracy 0.9361110925674438\n",
      "epoch : 77: train error : 0.15924722561612725, validation error : 0.19789719581604004,val accuracy 0.9361110925674438\n",
      "epoch : 78: train error : 0.15746687756230435, validation error : 0.19704672694206238,val accuracy 0.9361110925674438\n",
      "epoch : 79: train error : 0.15547428055045506, validation error : 0.19447804987430573,val accuracy 0.9388889074325562\n",
      "epoch : 80: train error : 0.15397641621530056, validation error : 0.19380615651607513,val accuracy 0.9416666626930237\n",
      "epoch : 81: train error : 0.1523829713308563, validation error : 0.19361725449562073,val accuracy 0.9416666626930237\n",
      "epoch : 82: train error : 0.15091105884251496, validation error : 0.193415105342865,val accuracy 0.9416666626930237\n",
      "epoch : 83: train error : 0.14942426901931563, validation error : 0.19020980596542358,val accuracy 0.9388889074325562\n",
      "epoch : 84: train error : 0.14773029981491467, validation error : 0.19072622060775757,val accuracy 0.9416666626930237\n",
      "epoch : 85: train error : 0.14629304315894842, validation error : 0.1882128119468689,val accuracy 0.9361110925674438\n",
      "epoch : 86: train error : 0.14523426187224686, validation error : 0.18666067719459534,val accuracy 0.9388889074325562\n",
      "epoch : 87: train error : 0.14367434002148607, validation error : 0.1867707520723343,val accuracy 0.9416666626930237\n",
      "epoch : 88: train error : 0.14194651448633522, validation error : 0.18693658709526062,val accuracy 0.9416666626930237\n",
      "epoch : 89: train error : 0.14066118964304528, validation error : 0.18398301303386688,val accuracy 0.9388889074325562\n",
      "epoch : 90: train error : 0.13959335597852865, validation error : 0.18302537500858307,val accuracy 0.9416666626930237\n",
      "epoch : 91: train error : 0.13755634155434868, validation error : 0.18536679446697235,val accuracy 0.9416666626930237\n",
      "epoch : 92: train error : 0.13721449975855649, validation error : 0.1815747320652008,val accuracy 0.9388889074325562\n",
      "epoch : 93: train error : 0.1358243217691779, validation error : 0.18003502488136292,val accuracy 0.9388889074325562\n",
      "epoch : 94: train error : 0.13460339982217798, validation error : 0.18013592064380646,val accuracy 0.9388889074325562\n",
      "epoch : 95: train error : 0.13304893819925687, validation error : 0.17808562517166138,val accuracy 0.9416666626930237\n",
      "epoch : 96: train error : 0.13200887486649057, validation error : 0.1792035847902298,val accuracy 0.9388889074325562\n",
      "epoch : 97: train error : 0.13127246305036047, validation error : 0.17729899287223816,val accuracy 0.9416666626930237\n",
      "epoch : 98: train error : 0.12977853533811867, validation error : 0.17585979402065277,val accuracy 0.9416666626930237\n",
      "epoch : 99: train error : 0.12899599818047136, validation error : 0.1756439059972763,val accuracy 0.9416666626930237\n"
     ]
    }
   ],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_features, out_features, n):\n",
    "        self.W = torch.randn((out_features, in_features)) * torch.sqrt(torch.tensor(2.0 / in_features))\n",
    "        self.W.requires_grad = True\n",
    "        self.b = torch.zeros((1, out_features), requires_grad=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.Z = X @ self.W.T + self.b\n",
    "        return self.Z\n",
    "\n",
    "    def backward(self, Z):\n",
    "        self.W.grad_ = Z.grad_.T @ self.X\n",
    "        self.b.grad_ = torch.sum(Z.grad_, dim=0)\n",
    "        self.X.grad_ = Z.grad_ @ self.W\n",
    "        return self.X.grad_\n",
    "\n",
    "class ReLU():\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return X.clamp_min(0.)\n",
    "\n",
    "    def backward(self, A):\n",
    "        return A.grad_ * (self.X > 0).float()\n",
    "\n",
    "class SoftmaxCrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        e_x = torch.exp(X - torch.max(X, dim=-1, keepdim=True)[0])\n",
    "        self.softmax_out = e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "\n",
    "        log_probs = torch.log(self.softmax_out + 1e-10)\n",
    "        target_log_probs = log_probs * y\n",
    "\n",
    "        self.loss = -target_log_probs.sum(dim=-1).mean()\n",
    "        return self.loss\n",
    "    def backward(self, y):\n",
    "        return (self.softmax_out - y) / y.shape[0]\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, input_features, hidden_units, output_units, data_num):\n",
    "        self.linear1 = Linear(input_features, hidden_units, data_num)\n",
    "        self.relu = ReLU()\n",
    "        self.linear2 = Linear(hidden_units, output_units, data_num)\n",
    "        self.loss_fn = SoftmaxCrossEntropy()\n",
    "\n",
    "    def forward(self, X, y):\n",
    "        self.X = X\n",
    "        self.Z1 = self.linear1.forward(X)\n",
    "        self.A1 = self.relu.forward(self.Z1)\n",
    "        self.Z2 = self.linear2.forward(self.A1)\n",
    "        self.loss = self.loss_fn.forward(self.Z2, y)\n",
    "        return self.loss, self.Z2\n",
    "\n",
    "    def backward(self, y):\n",
    "        self.Z2.grad_ = self.loss_fn.backward(y)\n",
    "        self.A1.grad_ = self.linear2.backward(self.Z2)\n",
    "        self.Z1.grad_ = self.relu.backward(self.A1)\n",
    "        self.X.grad_ = self.linear1.backward(self.Z1)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        # 勾配の初期化\n",
    "        self.linear1.W.grad_ = None\n",
    "        self.linear1.b.grad_ = None\n",
    "        self.linear2.W.grad_ = None\n",
    "        self.linear2.b.grad_ = None\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        # パラメータの更新\n",
    "        self.linear1.W -= learning_rate * self.linear1.W.grad_\n",
    "        self.linear1.b -= learning_rate * self.linear1.b.grad_\n",
    "        self.linear2.W -= learning_rate * self.linear2.W.grad_\n",
    "        self.linear2.b -= learning_rate * self.linear2.b.grad_\n",
    "\n",
    "## Refactoring後の学習ループ(OptimizerやDataset, Dataloaderの後にRefactaring)\n",
    "# ===データの準備===\n",
    "dataset = datasets.load_digits()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "X_mean = X_train.mean()\n",
    "X_std = X_train.std()\n",
    "\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_val  = (X_val  - X_mean ) / X_std\n",
    "\n",
    "X_train = torch.tensor(X_train.reshape(-1, 64), dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val.reshape(-1, 64), dtype=torch.float32)\n",
    "y_train = F.one_hot(torch.tensor(y_train), num_classes=10)\n",
    "y_val = F.one_hot(torch.tensor(y_val), num_classes=10)\n",
    "\n",
    "batch_size = 30\n",
    "# モデルの初期化\n",
    "model = Model(input_features=64, hidden_units=10, output_units=10, data_num = batch_size)\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# ログ\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    # エポックごとにデータをシャッフルする\n",
    "    shuffled_indices = np.random.permutation(len(y_train))\n",
    "    num_batches = np.ceil(len(y_train)/batch_size).astype(int)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i in range(num_batches):\n",
    "    \n",
    "        # mini batchの作成\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "    \n",
    "        batch_indices = shuffled_indices[start:end]\n",
    "        y_true_ = y_train[batch_indices, :] # batch_size x 10\n",
    "    \n",
    "        X = X_train[batch_indices, :] # batc_size x 64\n",
    "        # 順伝播と逆伝播の計算\n",
    "        loss, _ = model.forward(X, y_true_)\n",
    "        model.backward(y_true_)\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "        # パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            model.step(learning_rate)\n",
    "    \n",
    "        model.zero_grad()\n",
    "\n",
    "    # validtion\n",
    "    with torch.no_grad():\n",
    "        val_loss, Z2_val = model.forward(X_val, y_val)\n",
    "\n",
    "        val_accuracy = torch.sum(torch.argmax(Z2_val, dim=-1) == torch.argmax(y_val, dim=-1)) / y_val.shape[0]\n",
    "\n",
    "    train_losses.append(running_loss/num_batches)\n",
    "    val_losses.append(val_loss.item())\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    print(f'epoch : {epoch}: train error : {running_loss/num_batches}, validation error : {val_loss.item()},val accuracy {val_accuracy.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49657ef6-42a3-4de0-967b-02acd57b4a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([360, 10])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16089db1-fe85-4797-86fd-0351556c097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    return e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "\n",
    "# cross_entropy\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    return torch.sum(y_true * torch.log(y_pred)) / y_true.shape[0]\n",
    "\n",
    "# softmax関数とcross_entropyを一つにまとめる\n",
    "def softmax_cross_entropy(x, y_true):\n",
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    softmax_out = e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "    loss = -torch.sum(y_true * torch.log(softmax_out + 1e-10)) / y_true.shape[0]\n",
    "    return loss, softmax_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa22c2-aabe-47c7-8061-bd918e7169fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b03c9c-2af8-44b2-ac3f-bf2cdcd49c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b64f2-a294-42b7-a43c-eef7cf7a316d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef66d52-4f07-413c-b86f-ba950de1d5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b268f7-efcc-4a8c-85a7-fbab24241bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115cc11-3207-44a5-ae59-82fa662d3080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107b150-770f-47ab-9e18-42d0d10457a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bc490-0ed5-4a75-b55f-1bd495f9387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e01e2d0-6278-4ed7-8200-b858bee0ea18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7943dba9-45ce-4f24-ac2a-ee9e490554bb",
   "metadata": {},
   "source": [
    "## MNISTで多項ロジスティック回帰を学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe1f3fc-611b-4cc9-ba93-3c024a523231",
   "metadata": {},
   "source": [
    "### 1. データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a0d5b118-e4f9-45a6-9210-6b06ddacbc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ\n",
    "import torch\n",
    "from sklearn import datasets \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8a4d4b09-84f1-435a-908a-688b711588ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. データロード\n",
    "\n",
    "dataset = datasets.load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "89b025a7-58a6-470d-9f29-66c5bf32f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データ\n",
    "images = dataset['images']\n",
    "\n",
    "# 正解レベル\n",
    "target = dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f5fd2965-663f-4518-931b-6c39517fe604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "画像データのshape (1797, 8, 8)\n",
      "正解ラベルのshape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# データの確認\n",
    "print('画像データのshape', images.shape)\n",
    "print('正解ラベルのshape', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c858dd2-c1f0-4a73-be7f-a4db922f68de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2aabdf0d8820>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imageを可視化して確かめる\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 画像を表示するのは, plt.imshow()\n",
    "# これが1797枚ある\n",
    "plt.imshow(images[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceed2bdc-a60d-4abc-8ba1-591e8e22236d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62e4bc61-088c-422a-867f-e6120c93cd36",
   "metadata": {},
   "source": [
    "### 2. 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef88d942-dc99-4da2-b848-31e70b3f1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルのエンコーディング(one-hotエンコーディング)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# この形ではダメ、なぜなら、numpyの形を取ってはいけない -> tensorの形に！\n",
    "# あとは、引数にクラスの数を指定, num_classes\n",
    "# F.one_hot(target)\n",
    "\n",
    "y_true = F.one_hot(torch.tensor(target), num_classes=10)\n",
    "\n",
    "# imagesもnumpy arrayなので、tensorにする。また、numpy arrayはfloat64型なので型変換する\n",
    "# さらに、１次元配列として扱うので8x8 = 64の特徴量として扱うのでshapeを変える。\n",
    "# 今のshapeはimage.shape -> (1797, 8, 8) -> (1797, 64)にする\n",
    "images = torch.tensor(images, dtype=torch.float32).reshape(-1, 64)\n",
    "images = (images - images.mean()) / images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ab656df8-3dc2-4cc3-9ef0-62e62c84d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習率の準備\n",
    "learning_rate = 0.3\n",
    "\n",
    "# 各イテレーションの損失を入れる\n",
    "loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e99e33-1ea3-453d-8af0-f70b8201916a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69b8c016-85c2-436b-8e5c-c349b69a3f31",
   "metadata": {},
   "source": [
    "### 3. パラメータの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "653d887a-e64c-430e-a88b-0f30aa416dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wは10 x 64(出力 x 入力), b = 1 x 10 ( 1 x 出力)\n",
    "W = torch.rand((10, 64), requires_grad=True)\n",
    "b = torch.rand((1, 10), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6914ff-4ee4-4435-861b-09545bfc54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fc925-d45d-4209-afd0-418e85374dcd",
   "metadata": {},
   "source": [
    "### 4. softmaxの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "258f08ff-866e-42f4-985b-e180d494a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xは行列,\n",
    "# torch.max(x)はデータごと, 行ごとのmaxを取る。データが3x10だとすると、最大値は3x1にしたい\n",
    "# 左からrankを0とすると、rankを1とする、\n",
    "def softmax(x):\n",
    "    # 分子\n",
    "    e_x = torch.exp(x - torch.max(x, dim=-1, keepdim=True)[0])\n",
    "    # 分母\n",
    "    return e_x / (torch.sum(e_x, dim=-1, keepdim=True) + 1e-10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafb7fa-1b72-4b66-9acb-57474fb6a611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4c975628-08c4-4956-ad85-7527559ab795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2040, 0.2810, 0.1824, 0.8543, 0.3576],\n",
       "        [0.3684, 0.4519, 0.0455, 0.9556, 0.6813],\n",
       "        [0.9110, 0.9007, 0.2039, 0.0696, 0.4859]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((3, 5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3e9343f7-630e-4d80-985e-c7108215dbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.8543, 0.9556, 0.9110]),\n",
       "indices=tensor([3, 3, 0]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 行ごとの最大値\n",
    "torch.max(a, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3c4ca0c7-8086-4a80-b13e-eefaa3bf1d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8543],\n",
       "        [0.9556],\n",
       "        [0.9110]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 形状を保つ\n",
    "# これは2つ出力して、値と元のtensorのindexが何かを示している。-> 最大値だけを出力\n",
    "torch.max(a, dim=-1, keepdim=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e45e15c9-6f74-4d0e-8e50-95edc892b0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8793],\n",
       "        [2.5027],\n",
       "        [2.5711]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 行ごとにsumを取る\n",
    "torch.sum(a, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a38e6028-52f6-47b9-8764-fb4d7cc71e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5219, 0.5637, 0.5107, 1.0000, 0.6085],\n",
       "        [0.5559, 0.6043, 0.4025, 1.0000, 0.7601],\n",
       "        [1.0000, 0.9897, 0.4931, 0.4311, 0.6537]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(a - torch.max(a, dim=-1, keepdim=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0a7ae-c5d6-4aa6-a19c-64c5e80bb68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "014f2a23-435b-455a-a3ba-f16bb0ef1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropyの実装\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    # sumはスカラー(一つの値)で出力されるので、軸は関係ない\n",
    "    \n",
    "    return -torch.sum(y_true * torch.log(y_pred + 1e-10)) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf84e9-4c75-4caa-8373-421b99491680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c65550a-e99b-46b1-825a-4c49bc63b2f8",
   "metadata": {},
   "source": [
    "### 5. for文で学習ループ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5390d97d-4612-4cdd-a8a0-451d67ef3044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1: 0.8749518766135855\n",
      "epoch : 2: 0.4122171392897248\n",
      "epoch : 3: 0.40823457040378636\n",
      "epoch : 4: 0.3457045211614563\n",
      "epoch : 5: 0.2705396815343605\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    running_loss = 0\n",
    "    # それぞれのepochではデータを持ってきて、zを計算損失計算、softmax計算\n",
    "    for i in range(len(target)):\n",
    "        # 6. 入力データxおよび教師ラベルyを作成\n",
    "        y_true_ = y_true[i].reshape(-1, 10)  # データ数 x　クラス数\n",
    "        X = images[i].reshape(-1, 64)  # データ数 x 特徴量\n",
    "\n",
    "        # 7. z計算\n",
    "        Z = X@W.T + b\n",
    "\n",
    "        # 8.softmaxで予測計算\n",
    "        y_pred = softmax(Z)\n",
    "\n",
    "        # 9. 損失計算\n",
    "        loss = cross_entropy(y_true_, y_pred)\n",
    "        # lossはtensorの形なので、.item()を使って数値にする\n",
    "        loss_log.append(loss.item())\n",
    "        # epochごとのlossを計算する\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 10. 勾配を計算する\n",
    "        loss.backward()\n",
    "\n",
    "        # 11. パラメータ更新\n",
    "        with torch.no_grad():\n",
    "            W -= learning_rate * W.grad\n",
    "            b -= learning_rate * b.grad\n",
    "\n",
    "        # 12. 勾配初期化\n",
    "        W.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "\n",
    "    # 13. 損失logを出力\n",
    "    print(f'epoch : {epoch+1}: {running_loss/len(target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7a6e0d9-27bb-494c-a397-c3bce9e469a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29/1672824624.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(images, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(images, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9146b572-a71c-483a-bdd7-aaf063e158f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = X@W.T + b\n",
    "y_pred = softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b7d8201b-e89a-49fd-b344-94b8d44cce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9572)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.argmax(y_pred, dim=-1) == torch.argmax(y_true, dim=-1)) / y_true.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbd8bd-96ca-4b62-8faa-d0a1932b8789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d68d85-de80-4a7f-ba50-9ffb47e0a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d2f02db3-8afd-402c-8d7f-8673096323ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = 正しく分類できた/全サンプル数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "428491f6-8a2b-4b94-807f-91ebf8cd4540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# これだと、1次元の配列になってしまう\n",
    "# .reshapeにすることで、行列の形にする。 データ数xクラス数\n",
    "y_true[0].reshape(-1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ba4d2248-25bd-4141-bc68-a049eda5cb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# これもデータ数x特徴量にしたいので行列の形にする -> reshape(-1, 64)\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6d80a622-388b-4377-83b8-7271ef1c7c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "y_true_ = y_true[i].reshape(-1, 10)  # データ数 x　クラス数\n",
    "X = images[i].reshape(-1, 64)  # データ数 x 特徴量\n",
    "\n",
    "# 7. z計算\n",
    "z = X@W.T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "35dd3e49-bf9c-4971-8f4c-8976a263bda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5403, -2.9949,  0.0164, -2.6487, -1.1139,  1.1483, -0.8260, -3.5608,\n",
       "         -0.6175, -1.4660]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dfdad40f-0c73-4e6b-85ba-6401aaf88d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "01e44ed3-ef5a-41ac-b220-03b83ea1d369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "74387577-bc11-4c5f-bed9-a9ad74756f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c57d27cc-8bd4-4127-a14d-1c5157a4601b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "02ab8f89-d26b-4b2e-8d77-de4dd4f704ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = softmax(z)\n",
    "loss = cross_entropy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "493514ce-9ce0-4943-ad6f-e811285c431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9479fafc-c8a0-4a69-b46a-7294afb5b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037221a9-b002-4ad0-abdd-5ad78e4e48d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d4bfa-8bc9-4d9c-98de-8fe4ac293d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d15e15-713b-4bd9-8744-5a16f07a3249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2663c-2459-4151-ac58-c5d41e73e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
